trainer:
  device: gpu
  epochs: 250
  logs: "logs"
  experiment: "test"
model:
  class: models.BasicLstmChatter
  parameters:
    max_length: 100
    layers: 2
    do: 0.5
    hidden_size: 256
    embedding_dim: 128
optimizer:
  class: torch.optim.RMSprop
  parameters:
    lr: 0.01
    weight_decay: 0.0
tokenizer:
  class: tokenizers.SimpleTokenizer
  parameters:
    path: "data/tokenizers/tokenizer_2/vocab.json"
dataset:
  class: datasets.ChatDataset
  parameters:
    path: "data/datasets/dataset_2/dataset.csv"
    max_words: 100
    limit: -1
  valid_share: 0.01
  train_batch: 64
  valid_batch: 64
  num_workers: 4
criterion:
  class: criterions.MaskedCrossEntropy
